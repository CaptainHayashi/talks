Verifying a Single-Producer Stack
11.50, 16 Jul 2015
Tags: concurrency sppool safety icap

*Matt*Windsor*
University of York
mbw500@york.ac.uk

Mike Dodds
University of York
mike.dodds@york.ac.uk

# Hi, I'm Matt, and I'm from the High-Integrity Systems Engineering
# research group at the University of York.  I'm currently in my first
# year of a Ph.D supervised by Mike Dodds.
#
# This is the first time I've talked at a workshop, so your feedback is
# greatly appreciated.

# So, let's talk about verifying a stack.

*  
.image sppool0.png

# We're going to be looking at the SP pool, which is part of the
# time-stamped stack Mike Dodds, Andreas Haas, and Christoph Kirsch
# discussed at POPL this year.

# The SP pool is made up of nodes containing an element, as well as a
# next pointer and a boolean flag symbolising takenness.

*  
.image sppool1.png

# These nodes form a linked listâ€¦

*  
.image sppool2.png

# â€¦terminating in a special node that links back to itself, which we
# term the sentinel node.

*  
.image sppool3.png

# Of course, there is also a top pointer.  Everything from this down
# to but excluding the sentinel is considered a node.

*  
.image sppool4.png

# The SP pool is single-producer, with one thread taking the push
# operation.

* Pushing

# Pushing is fairly straightforward, and involves making a node,
# giving it the top pointer, and then assigning it to the SP pool's top.
# We're assuming assignment is atomic here.

Non-atomic node creation, atomic top swap.

.code sppool /INSERT OMIT/,/END INSERT OMIT/

Unsound in general, but our pool is single-producer, so it works.

*  
.image sppool5.png

# The SP pool is multi-consumer, with multiple threads being able to
# pop.  The pop occurs in two stages:

* Popping

Non-atomically find the youngest node (or report empty)â€¦

.code sppool /GETYOUNGEST OMIT/,/END GETYOUNGEST OMIT/

â€¦and atomically mark it as _taken_.

.code sppool /REMOVE OMIT/,/END REMOVE OMIT/

# This wraps up the stack methods of the pool.  So far this looks fairly
# simple and easy to prove, but I wouldn't be talking about it if it
# was!  So, we're not finished.

* Compression

# You might have noticed that our pool has a memory leak in it.

_insert_ adds nodes, but _remove_ doesn't remove them â‡’ _memory_leak._

Solution: _atomically_ move pointers past taken nodes
â€” take taken nodes out of main pool (_spine_)

* Forwards compression

Non-atomically sweep all taken nodes below current node, then swing next pointer.

  Node next = newNode.next;
  while (next->next != next && node.taken) next = next->next;
  newNode.next = next;

.image fcom.png

* Backwards compression

_getYoungest_ sweeps only taken nodes between top and youngest node, so:

  CAS(top, oldTop, node);
  if (oldTop != node) oldTop.next = node;

# We assume reference counting and ABA counters here.

.image bcom.png

* Compression
.image fraying0.png

Without compression, we have a trivial linked listâ€¦

* Compression
.image fraying1.png

* Compression
.image fraying2.png

This is still a linked listâ€¦ right?

# So, if we're doing this, then we still have a linked list, right?
# All these red branches are unused nodes that we're just pulling out of
# the spine, right?

* Wrong
Non-atomic traversals â†’ traversals moved out _with_taken_nodes_

.image fraying3.png

* Okâ€¦ but at least there aren't any data-races
So far the only obvious race (insert-insert) has been mitigated by SP.

Butâ€¦ what about compression-compression?

* Forwards compression âˆ¥ Forwards compression
A is inserted; all between A and B taken; compression begins

.image race0.png

* Forwards compression âˆ¥ Forwards compression
Compression sweeps to B, which is not taken

.image race1.png

* Forwards compression âˆ¥ Forwards compression
_Context_switch_ to removal of B; all between B and C also taken

.image race2.png

* Forwards compression âˆ¥ Forwards compression
_Context_switch_ to removal of A; new compression run sweeps to C

.image race3.png

* Forwards compression âˆ¥ Forwards compression
If new run updates pointer firstâ€¦

.image race4.png

* Forwards compression âˆ¥ Forwards compression
â€¦part of it is undone by old run when it resumes

.image race5.png

(Also a similar backwards-compression race with insertion!)

* Harmless data-races?

Can we show that these don't violate well-formedness invariants?

- All non-taken nodes being on spine, no cycles, etc.
- These races only undo some compression: unwanted, but _harmless._
- Removing them wasteful?

Let's find outâ€¦

* Introducing iCAP

Higher-order concurrent separation logic based on CAP, RGSep, â€¦, Reynolds.

- Shared state is labelled transition system (protocol)
- Transitions require threads to have (fractional) permission.

*What*exactly*are*we*proving?*

- _Memory_safety_ (well-formedness invariants)
- linearizability to a stack better, but more difficult

Proof is mainly carried out using an abstraction of the states of the SP pool

# Next-pointer order is subset of insertion order
# Each node has one, and only one, next pointer
# Sentinel is the only node to point to itself
# Each node must have a path to the sentinel
# Only the spine can have non-taken nodes
# No node can be both taken and non-taken
# Methods adhere to _weak_ preconditions and postconditions


* The abstract state
Each state is a _6-tuple_ of nodes and _sets_ of nodes:

.image tuple0.png

* The abstract state
Each state is a _6-tuple_ of nodes and _sets_ of nodes:

.image tuple1.png
# We have the sets of taken and non-taken nodesâ€¦

* The abstract state
Each state is a _6-tuple_ of nodes and _sets_ of nodes:

.image tuple2.png
# â€¦the top and sentinel nodes, which must be in N union Tâ€¦

* The abstract state
Each state is a _6-tuple_ of nodes and _sets_ of nodes:

.image tuple3.png
# â€¦and two sets of pointers as ordered set pairs, one of which is the
# literal physical next pointer set that can be closed over to make a
# partial physical order, and the other is added to every
# time a node is inserted, and can be used to make a total insertion
# order.

â‰¤ğ“Ÿ â‰œ reflexive transitive closure of ğ“Ÿ
â€”_physical_order_
â‰¤ğ“£ â‰œ reflexive transitive closure of ğ“£
â€”_temporal_(insertion)_order_

* The abstract state is a monolithic tuple
.image framing.png
No _separation._  No _framing._

Actions affect only one or two nodes, but we have to reason about the _whole_pool_.

Not a deal breaker, but complicates proof.

# SP pool not a good fit for transition systems?: not a finite state machine.

* What do invariants look like?

Invariants need to be general enough to cope with a constantly shifting pool

.image fraying3.png

Let's look at an exampleâ€¦

* Invariant for forwards compression

*Forwards*compression*of*a*from*b*to*c:*
âŸ¨N, T, t, s, ğ“Ÿ âŠ {(a, b)}, ğ“£âŸ© âˆ§ a >ğ“£ c âˆ§ allTaken(b, c, T, ğ“Ÿ, ğ“£) âŸ¿ âŸ¨N, T, t, s, ğ“Ÿ âŠ {(a, c)}, ğ“£âŸ©

# Compression need not be between two points on the same branch
# â€¦but both sides must be _taken_

.image compress.png

How to show both sides are taken?  That the compression can't make cycles?

* Invariant for forwards compression

.image compress2.png

# If we apply the insertion order here, then we can simply say that

â‰¤ğ“Ÿ âŠ† â‰¤ğ“£, â‰¤ğ“£ total, and â‰¤ğ“£ monotonic; compression preserves _illusion_ that â‰¤ğ“Ÿ = â‰¤ğ“£

* What can I conclude?

* Conclusions

Simple code doesn't mean simple proofs.

- Data-races can make things very difficult
- Linearisability not easily shown

iCAP works but could fit better.

- Abstraction is good!, butâ€¦
- â€¦no framing, no separation
- proof needs to reason about _all_ interference all the time, so massive stability proofs
- Tree logics?

Proof not yet finished: too informal, probably some bugs.
But results look promising.
